<?xml version="1.0"?>
<section xml:id="scale-free-networks_heavy-tailed-distributions">
  <title>Heavy-tailed Distributions</title>
  <figure align="center" xml:id="sfn-fig-2">
    <caption xmlns:c="https://www.sphinx-doc.org/" xmlns:changeset="https://www.sphinx-doc.org/" xmlns:citation="https://www.sphinx-doc.org/" xmlns:cpp="https://www.sphinx-doc.org/" xmlns:index="https://www.sphinx-doc.org/" xmlns:js="https://www.sphinx-doc.org/" xmlns:math="https://www.sphinx-doc.org/" xmlns:py="https://www.sphinx-doc.org/" xmlns:rst="https://www.sphinx-doc.org/" xmlns:std="https://www.sphinx-doc.org/"> PMF of degree in the Facebook dataset and in the WS model, on a log-log scale.</caption>
    <image source="ScaleFreeNetworks/Figures/thinkcomplexity2011.png" width="50%" >
      <shortdescription>PMF of degree in the Facebook dataset and in the WS model, on a log-log scale.</shortdescription>
      <description>
        <p>This figure presents the same Probability Mass Functions (PMFs) of node degrees for the Facebook dataset and the Watts-Strogatz (WS) model that were shown in the previous figure. However, this plot uses a log-log scale, meaning both the x-axis (representing degree k) and the y-axis (representing probability P(k)) are scaled logarithmically.</p>
        <p>The change to a log-log scale significantly alters the visual representation of these distributions. The WS model's distribution typically remains compact, while the tail of the Facebook dataset's distribution is emphasized. The accompanying text discusses how this transformation can reveal underlying patterns, such as the appearance of a nearly straight line for the Facebook data, which is indicative of a power-law relationship explained in the text.</p>
      </description> </image>
  </figure>
  <p><term>Heavy-tailed distributions</term> are a common feature in many areas of complexity science and they will be a recurring theme of this book.</p>
  <p>We can get a clearer picture of a heavy-tailed distribution by plotting it on a log-log axis, as shown in <xref ref="sfn-fig-2"/>. This transformation emphasizes the tail of the distribution; that is, the probabilities of large values.</p>
  <p>Under this transformation, the data fall approximately on a straight line, which suggests that there is a <term>power law</term> relationship between the largest values in the distribution and their probabilities. Mathematically, a distribution obeys a power law if <m>PMF(k) &#x223C; k&#x2212;&#x3B1;</m> where <c>PMF(k)</c> is the fraction of nodes with degree <c>k</c>, <c>&#x3B1;</c> is a parameter, and the symbol &#x223C; indicates that the <c>PMF</c> is asymptotic to <c>k&#x2212;&#x3B1;</c> as <c>k</c> increases.</p>
  <p>If we take the log of both sides, we get:</p>
  <math_block docname="ScaleFreeNetworks/HeavyTailedDistributions" label="True" nowrap="False" number="True" xml:space="preserve">logPMF(k) &#x223C; &#x2212;&#x3B1; logk</math_block>
  <p>So if a distribution follows a power law and we plot <c>PMF(k)</c> versus <c>k</c> on a log-log scale, we expect a straight line with slope <c>&#x2212;&#x3B1;</c>, at least for large values of <c>k</c>.</p>
  <p>All power law distributions are heavy-tailed, but there are other heavy-tailed distributions that don't follow a power law. We will see more examples soon.</p>
  <p>But first, we have a problem: the WS model has the high clustering and low path length we see in the data, but the degree distribution doesn't resemble the data at all. This discrepancy is the motivation for our next topic, the Barab&#xE1;si-Albert model.</p>
</section>
