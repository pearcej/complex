..  Copyright (C)  Brad Miller, David Ranum, and Jan Pearce
    This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/.


Complexity Thinking
-------------------

We are getting farther afield now, but the shifts I am postulating in the criteria of scientific modeling are related to 20th century developments in logic and epistemology.

**Aristotelian logic→many-valued logic**

In  traditional  logic,  any  proposition is either true or false.  This system lends itself to math-like proofs, but fails (in dramatic ways) for many real-world applications.  Alternatives include many-valued logic, fuzzy logic, and other systems designed to handle indeterminacy,  vagueness,  and uncertainty.  Bart Kosko dis-cusses some of these systems in *Fuzzy Thinking*.

**Frequentist probability→Bayesianism**

Bayesian probability has been around for centuries, but was not widely used until recently, facilitated by the availability of cheap computation and the reluctant acceptance of subjectivity in probabilistic claims.  Sharon Bertsch McGrayne presents this history in *The Theory That Would Not Die*.

**Objective→subjective**

The Enlightenment,  and philosophic  modernism, are based on belief in objective truth, that is, truths that are independent of the people that hold them.  20th century developments including quantum mechanics, Godel’s Incompleteness Theorem, and Kuhn’s study of the history of science called attention to seemingly unavoidable subjectivity in even “hard sciences” and mathematics.  Rebecca Gold-stein presents the historical context of Godel’s proof in *Incompleteness*.

**Physical law→theory→model**

Some  people  distinguish  between  laws, theories, and models.  Calling something a “law” implies that it is objectively  true  and  immutable;  “theory”  suggests  that  it  is  subject  to revision;  and “model” concedes that it is a subjective choice based on simplifications and approximations.

I think they are all the same thing.  Some concepts that are called laws are really definitions;  others are,  in effect,  the assertion that a certain model  predicts  or  explains  the  behavior  of  a  system  particularly  well. We come back to the nature of physical laws in :ref:`Section 5.9 <5.9>`, :ref:`Section 6.9 <6.9>`, and :ref:`Section 9.9 <9.9>`

**Determinism→indeterminism**

Determinism  is  the  view  that  all  events are caused, inevitably, by prior events.  Forms of indeterminism include randomness, probabilistic causation, and fundamental uncertainty.  We will come back to this topic in :ref:`Section 6.6 <6.6>` and :ref:`Section 11.7 <11.7>`

This chapter is an overview of the themes coming up in the book, but not all of it will make sense before you see the examples.  When you get to the end of the book, you might find it helpful to read this chapter again.

.. _Chapter 5.9: http://localhost:8000/Scale-free%20networks/Explanatory%20models.html

.. _Chapter 6.9: http://localhost:8000/Cellular%20Automatons/WhatIsThisAModelOf.html

.. _Chapter 9.9: http://localhost:8000/Self-organized%20criticality/Reductionism%20and%20Holism.html

.. _Chapter 6.5: http://localhost:8000/Cellular%20Automatons/Determinism.html

.. _Chapter 11.7: http://localhost:8000/Herds,%20Flocks,%20and%20Traffic%20Jams/Emergence%20and%20free%20will.html


